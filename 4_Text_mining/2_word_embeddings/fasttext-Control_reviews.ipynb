{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "554bc248",
   "metadata": {},
   "source": [
    "## Downloading fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd188e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "# !git clone https://github.com/facebookresearch/fastText.git\n",
    "# !cd fastText\n",
    "# !pip install fastText\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import pandas as pd\n",
    "import ast\n",
    "from numpy import mean\n",
    "import pickle\n",
    "# download an english model of fasttext\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "970d6c6d",
   "metadata": {},
   "source": [
    "## Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61a5d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=pd.read_csv(\"FPS_reviews_lemmatized.csv\")\n",
    "with open(\"control_recommendation_ids_all.pkl\", \"rb\") as fp1:\n",
    "  control_id = pickle.load(fp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184c93ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 920536/920536 [00:00<00:00, 3016450.07it/s]\n",
      "100%|█████████████████████████████████| 920536/920536 [08:03<00:00, 1905.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "with open(\"recommendation_id.pkl\", \"rb\") as fp2:\n",
    "  recommendation_ids = pickle.load(fp2)\n",
    "recommendation_ids = [str(elem) for elem in tqdm(recommendation_ids)]\n",
    "control_id=[[str(elem) for elem in inner_list] for (inner_list) in tqdm(control_id)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2bc86f0",
   "metadata": {},
   "source": [
    "## Computing fastText and the cosine-similarity matrices\n",
    "\n",
    "Saving in chunks due to the massive size of the control files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f627772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████████████████████████| 1056940/1056940 [00:44<00:00, 23765.06it/s]\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "# getting the fastText word vectors for each reviews\n",
    "def get_vector(s):\n",
    "  return (model.get_sentence_vector(str(s)))\n",
    "\n",
    "# getting the fastText word vectors for across all reviews and saving it in the form of a dictionary\n",
    "def get_vector_dict(reviews):\n",
    "  review_ids=list(reviews[\"recommendation_id\"])\n",
    "  review=list(reviews[\"review\"])\n",
    "  vector={}\n",
    "  for i in tqdm(range(len(review))):\n",
    "    review_id=str(review_ids[i])\n",
    "    fasttext_vector=get_vector(review[i])\n",
    "    vector[review_id]=fasttext_vector\n",
    "  return(vector)\n",
    "\n",
    "# calculating the cosine-similarity score \n",
    "def cosine_similarity(embedding_1, embedding_2):\n",
    "  # Calculate the cosine similarity of the two embeddings.\n",
    "  sim = 1 - cosine(embedding_1, embedding_2)\n",
    "  return(sim)\n",
    "\n",
    "# getting the cosine similarity matrix for each review\n",
    "def similiarity_matrix(list_of_reviews,recommendation_id,comments_vector):\n",
    "  review_id=str(recommendation_id)\n",
    "  review_vector=list(comments_vector[review_id])\n",
    "  matrix=[]\n",
    "  for i in range(0,len(list_of_reviews)):\n",
    "    order_id=str(list_of_reviews[i])\n",
    "    order_x=comments_vector[order_id]\n",
    "    similarity=cosine_similarity(review_vector,order_x)\n",
    "    matrix.append(similarity)\n",
    "  return(matrix)\n",
    "\n",
    "vector_dict=get_vector_dict(reviews)\n",
    "# compiling all the similarity matrices \n",
    "\n",
    "def list_of_matrix(review_order_list,comments_vector):\n",
    "  matrix_list=[]\n",
    "  for i in (range(len(review_order_list))):\n",
    "    recommendation_id=recommendation_ids[i]\n",
    "    list_of_visible_matrices=similiarity_matrix(list(review_order_list[i]),recommendation_id,comments_vector)\n",
    "    matrix_list.append(list_of_visible_matrices)\n",
    "  return(matrix_list)\n",
    "\n",
    "# Saving in chunks due to the massive size of the control files\n",
    "current,total=0,0\n",
    "while current<=len(recommendation_id):\n",
    "    #print(\"At\", current, \"to\", (current+1000))\n",
    "    control_id_current=control_id[current:current+1000]\n",
    "    i=str(current)+\"_to_\"+str(current+1000)\n",
    "    control_matrix=list_of_matrix(control_id_current,vector_dict)\n",
    "    # Open a new file for writing in binary mode\n",
    "    file_name=\"control_matrix_{}.pickle\".format(i)\n",
    "    with open(file_name, 'wb') as f:\n",
    "        # Use the pickle.dump() method to write the data to the file\n",
    "        pickle.dump(control_matrix, f)\n",
    "    current=current+1000\n",
    "    total=total+1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
