{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment these lines if the packages are not installed\n",
    "# pip install emot\n",
    "# pip install emoji\n",
    "# pip install gensim\n",
    "\n",
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from emot.emo_unicode import EMOJI_UNICODE, EMOTICONS_EMO  # For EMOTICONS and EMOJI\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import requests\n",
    "import emoji\n",
    "import types\n",
    "\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            try:\n",
    "                yield val.__name__, val.__version__\n",
    "                pass\n",
    "            except:\n",
    "                yield val.__name__\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "list(imports())\n",
    "\n",
    "# Reading data\n",
    "FPS_reviews = pd.read_csv(\"../data/raw_data/data_filtered.csv.gz\", compression=\"gzip\",low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "t33t50D6KACW"
   },
   "outputs": [],
   "source": [
    "# Deal with profanities profanities censored as '♥'\n",
    "def identify_profanities_1(selected_reviews):\n",
    "    \"\"\"\n",
    "    Identifies and replaces censored profanities in reviews, where the censorship character is '♥'.\n",
    "\n",
    "    Args:\n",
    "    selected_reviews: A list of reviews to process.\n",
    "\n",
    "    Returns:\n",
    "    A list of reviews with profanities uncensored.\n",
    "    \"\"\"\n",
    "    # download the .txt file from https://github.com/kast1450/steam-profanity-filter/blob/main/english/english-profanity.txt\n",
    "    with open(\"../data/supplemental_data/english-profanity.txt\", encoding='utf-8') as file: \n",
    "        profanity_list = [item.strip() for item in file]\n",
    "\n",
    "    profanity_dictionary = {}\n",
    "    for word in profanity_list:\n",
    "        censored = \"♥\" * len(word)\n",
    "        profanity_dictionary[word] = censored\n",
    "\n",
    "    for i in tqdm(range(len(selected_reviews))):\n",
    "        review = str(selected_reviews[i])\n",
    "        for profanity, censored_version in profanity_dictionary.items():\n",
    "            review = review.replace(censored_version, profanity)\n",
    "        selected_reviews[i] = review\n",
    "\n",
    "    return selected_reviews\n",
    "\n",
    "# Deal with profanities censored as '*'\n",
    "def identify_profanities_2(selected_reviews):\n",
    "    \"\"\"\n",
    "    Identifies and replaces censored profanities in reviews, where the censorship character is '*'.\n",
    "\n",
    "    Args:\n",
    "    selected_reviews: A list of reviews to process.\n",
    "\n",
    "    Returns:\n",
    "    A list of reviews with profanities uncensored.\n",
    "    \"\"\"\n",
    "    with open(\"../data/supplemental_data/english-profanity.txt\", encoding='utf-8') as file:\n",
    "        profanity_list = [item.strip() for item in file]\n",
    "\n",
    "    profanity_dictionary = {}\n",
    "    for word in profanity_list:\n",
    "        censored = \"*\" * len(word)\n",
    "        profanity_dictionary[word] = censored\n",
    "\n",
    "    for i in tqdm(range(len(selected_reviews))):\n",
    "        review = str(selected_reviews[i])\n",
    "        for profanity, censored_version in profanity_dictionary.items():\n",
    "            review = review.replace(censored_version, profanity)\n",
    "        selected_reviews[i] = review\n",
    "\n",
    "    return selected_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4vrw-G2_-iIp"
   },
   "outputs": [],
   "source": [
    "# Deal with URLs\n",
    "def remove_urls_https_and_www(selected_reviews):\n",
    "    \"\"\"\n",
    "    Removes URLs from the given list of reviews.\n",
    "\n",
    "    Args:\n",
    "    selected_reviews: A list of reviews.\n",
    "\n",
    "    Returns:\n",
    "    A list of reviews with URLs removed.\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(len(selected_reviews))):\n",
    "        review = str(selected_reviews[i])\n",
    "        patterns = [r\"url=https?://(www\\.)?\", r\"https?://(www\\.)?\",\n",
    "                    r\"www.?\", r\".com\\S+\"]\n",
    "        for pattern in patterns:\n",
    "            url = re.compile(pattern)\n",
    "            review = url.sub('', review).strip().strip('/')\n",
    "        selected_reviews[i] = review\n",
    "    return selected_reviews\n",
    "\n",
    "# Deal with emojis\n",
    "def convert_emojis_to_word(selected_review):\n",
    "    \"\"\"\n",
    "    Converts emojis in the reviews to their word representation.\n",
    "\n",
    "    Args:\n",
    "    selected_review: A list of reviews.\n",
    "\n",
    "    Returns:\n",
    "    A list of reviews with emojis converted to words.\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(len(selected_review))):\n",
    "        review = emoji.demojize(str(selected_review[i]), delimiters=(\"\", \" \"))\n",
    "        selected_review[i] = review\n",
    "    return selected_review\n",
    "\n",
    "# Deal with emoticons\n",
    "def convert_emoticons_to_word(selected_review):\n",
    "    \"\"\"\n",
    "    Converts emoticons in the reviews to their word representation.\n",
    "\n",
    "    Args:\n",
    "    selected_review: A list of reviews.\n",
    "\n",
    "    Returns:\n",
    "    A list of reviews with emoticons converted to words.\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(len(selected_review))):\n",
    "        review = str(selected_review[i])\n",
    "        for emot in EMOTICONS_EMO:\n",
    "            review = review.replace(emot, EMOTICONS_EMO[emot].replace(\" \", \"_\"))\n",
    "        selected_review[i] = review\n",
    "    return selected_review\n",
    "\n",
    "# Deal with casing\n",
    "def lower_case(selected_reviews):\n",
    "    \"\"\"\n",
    "    Converts all characters in the reviews to lower case.\n",
    "\n",
    "    Args:\n",
    "    selected_reviews: A list of reviews.\n",
    "\n",
    "    Returns:\n",
    "    A list of reviews in lower case.\n",
    "    \"\"\"\n",
    "    return [review.lower() for review in tqdm(selected_reviews)]\n",
    "\n",
    "# Deal with punctuation\n",
    "def remove_punctuation(selected_reviews):\n",
    "    \"\"\"\n",
    "    Removes punctuation from the reviews.\n",
    "\n",
    "    Args:\n",
    "    selected_reviews: A list of reviews.\n",
    "\n",
    "    Returns:\n",
    "    A list of reviews with punctuation removed.\n",
    "    \"\"\"\n",
    "    return [re.sub(r'[^A-Za-z0-9_]', ' ', str(review)) for review in tqdm(selected_reviews)]\n",
    "\n",
    "# Deal with stop-words\n",
    "def remove_stop_words(selected_reviews):\n",
    "    \"\"\"\n",
    "    Removes stop words from the reviews.\n",
    "\n",
    "    Args:\n",
    "    selected_reviews: A list of reviews.\n",
    "\n",
    "    Returns:\n",
    "    A list of reviews with stop words removed.\n",
    "    \"\"\"\n",
    "    # please download the file from here https://drive.google.com/file/d/1Mg1VFspYOembPVnZ3ocYBi9aC2Y8gRWR/view?usp=sharing\n",
    "    with open('../data/supplemental_data/stopwords-english') as f:\n",
    "        stopwords_list = f.read().splitlines()\n",
    "    return [remove_stopwords(str(review)) for review in tqdm(selected_reviews)]\n",
    "\n",
    "# Deal with double spacing\n",
    "def remove_spacing(selected_reviews):\n",
    "    \"\"\"\n",
    "    Removes extra spaces from the reviews.\n",
    "\n",
    "    Args:\n",
    "    selected_reviews: A list of reviews.\n",
    "\n",
    "    Returns:\n",
    "    A list of reviews with extra spaces removed.\n",
    "    \"\"\"\n",
    "    return [re.sub(r'\\s+', ' ', str(review), flags=re.I) for review in tqdm(selected_reviews)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1YDI-mvAIEx",
    "outputId": "9d30c786-087c-42dd-90ba-0fd3c39d8c54"
   },
   "outputs": [],
   "source": [
    "# Run the above functions and save the file.\n",
    "\n",
    "FPS_reviews[\"review\"] = identify_profanities_1(FPS_reviews[\"review\"].tolist())\n",
    "FPS_reviews[\"review\"] = identify_profanities_2(FPS_reviews[\"review\"].tolist())\n",
    "FPS_reviews[\"review\"] = remove_urls_https_and_www(FPS_reviews[\"review\"].tolist())\n",
    "FPS_reviews[\"review\"] = convert_emojis_to_word(FPS_reviews[\"review\"].tolist())\n",
    "FPS_reviews[\"review\"] = convert_emoticons_to_word(FPS_reviews[\"review\"].tolist())\n",
    "FPS_reviews[\"review\"] = lower_case(FPS_reviews[\"review\"].tolist())\n",
    "FPS_reviews[\"review\"] = remove_punctuation(FPS_reviews[\"review\"].tolist())\n",
    "FPS_reviews[\"review\"] = remove_stop_words(FPS_reviews[\"review\"].tolist())\n",
    "FPS_reviews[\"review\"] = remove_spacing(FPS_reviews[\"review\"].tolist())\n",
    "\n",
    "# Save the processed data to a CSV file\n",
    "FPS_reviews.to_csv('../data/interim_data/04_text_mining/preprocessed/reviews_preprocessed.csv.gz', index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
